# %% [markdown]
# # Traffic Classification for SDN
# **Mục tiêu:** Xây dựng mô hình AI để phân loại lưu lượng mạng (QoS Classification).
# **Input:** File CSV từ Mininet/Ryu.
# **Output:** Model tốt nhất (.pkl) và Scaler (.pkl) để nhúng vào Smart Controller.

# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib  # Để lưu model
import time

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

# Cấu hình hiển thị
plt.style.use('ggplot')
sns.set_palette("husl")

# %% [markdown]
# ## 1. Load & Preprocess Data

# %%
# Load dữ liệu
data_path = 'network_traffic_data.csv'
df = pd.read_csv(data_path)

print(f"Tổng số mẫu ban đầu: {df.shape[0]}")

# 1. Lọc bỏ nhiễu
# Chỉ giữ lại các nhãn quan trọng, loại bỏ control_traffic hoặc unknown
target_labels = ['video', 'voip', 'web', 'background']
df_clean = df[df['label'].isin(target_labels)].copy()

print(f"Số mẫu sau khi lọc: {df_clean.shape[0]}")
print("Phân bố dữ liệu:\n", df_clean['label'].value_counts())

# 2. Feature Selection (Quan trọng)
# BỎ: ip_src, ip_dst, src_port, dst_port (Để tránh model học vẹt địa chỉ/cổng)
# GIỮ: Các đặc trưng thống kê của luồng traffic
features = ['ip_proto', 'packet_count', 'byte_count', 
            'duration_sec', 'byte_rate', 'packet_rate']
target = 'label'

X = df_clean[features]
y = df_clean[target]

# 3. Label Encoding (Chuyển nhãn chữ sang số: 0, 1, 2, 3)
le = LabelEncoder()
y_encoded = le.fit_transform(y)
class_names = le.classes_
print(f"\nCác lớp mục tiêu: {class_names}")

# 4. Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)

# 5. Scaling (Chuẩn hóa dữ liệu)
# Rất quan trọng để đảm bảo tính ổn định cho model
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\nKích thước tập Train:", X_train_scaled.shape)
print("Kích thước tập Test:", X_test_scaled.shape)

# %% [markdown]
# ## 2. Train & Compare Models

# %%
# Khởi tạo 2 mô hình
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42, max_depth=10),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
}

results = {}
trained_models = {}

# Vòng lặp huấn luyện
for name, model in models.items():
    print(f"\nTraining {name}...")
    start_time = time.time()
    
    # Train
    model.fit(X_train_scaled, y_train)
    train_time = time.time() - start_time
    
    # Predict
    y_pred = model.predict(X_test_scaled)
    
    # Metrics
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    results[name] = {
        'Accuracy': acc,
        'F1-Score': f1,
        'Training Time (s)': train_time
    }
    trained_models[name] = model
    
    print(f"Done. Accuracy: {acc:.4f}")

# %% [markdown]
# ## 3. Evaluation & Visualization

# %%
# 1. So sánh Accuracy & F1-Score
results_df = pd.DataFrame(results).T
print("\n>>> BẢNG SO SÁNH HIỆU NĂNG:")
print(results_df)

# Vẽ biểu đồ so sánh
results_df[['Accuracy', 'F1-Score']].plot(kind='bar', figsize=(10, 6))
plt.title('So sánh Decision Tree vs Random Forest')
plt.ylabel('Score (0-1)')
plt.ylim(0.8, 1.05) # Zoom vào phần trên để thấy rõ sự khác biệt
plt.xticks(rotation=0)
plt.legend(loc='lower right')
plt.show()

# 2. Vẽ Confusion Matrix (Để xem model hay nhầm lẫn lớp nào)
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

for i, (name, model) in enumerate(trained_models.items()):
    y_pred = model.predict(X_test_scaled)
    cm = confusion_matrix(y_test, y_pred)
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],
                xticklabels=class_names, yticklabels=class_names)
    axes[i].set_title(f'{name} Confusion Matrix\nAcc: {results[name]["Accuracy"]:.4f}')
    axes[i].set_xlabel('Predicted Label')
    axes[i].set_ylabel('True Label')

plt.tight_layout()
plt.show()

# 3. Feature Importance (Chỉ xem của Random Forest)
rf_model = trained_models['Random Forest']
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 5))
plt.title("Độ quan trọng của các đặc trưng (Feature Importance)")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=45)
plt.tight_layout()
plt.show()

# %% [markdown]
# ## 4. Save Best Model

# %%
# Tự động chọn model tốt nhất dựa trên Accuracy
best_model_name = results_df['Accuracy'].idxmax()
best_model = trained_models[best_model_name]
best_acc = results_df.loc[best_model_name, 'Accuracy']

print(f"\n=> MÔ HÌNH TỐI ƯU NHẤT LÀ: {best_model_name} (Acc: {best_acc:.4f})")

# Lưu Model và Scaler và LabelEncoder
# Cần lưu cả Scaler vì Controller phải scale dữ liệu mới y hệt lúc train
joblib.dump(best_model, 'best_classifier_model.pkl')
joblib.dump(scaler, 'classifier_scaler.pkl')
joblib.dump(le, 'label_encoder.pkl')

print("Đã lưu model thành công: 'best_classifier_model.pkl', 'classifier_scaler.pkl'")
